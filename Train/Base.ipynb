{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchtext.legacy.data import Field, Dataset, Example,BucketIterator,Iterator\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from typing import List\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import codecs\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "from torchtext.legacy.datasets import SequenceTaggingDataset\n",
    "from ignite.metrics import RougeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff133ecc6f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SEED=2022\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(path,p0='train',p1='in'):\n",
    "    path=path+p0+'/'+p1+'.txt'\n",
    "    text_list=[]\n",
    "    for line in codecs.open(path, 'r', 'utf-8'):\n",
    "        #drop the final dimension\n",
    "        line=line.split(' ')[0:-1]\n",
    "        text_list.append(line)\n",
    "    return text_list\n",
    "\n",
    "root_path='./data/couplet-pro/'\n",
    "para0=['train','test']\n",
    "para1=['in','out']\n",
    "\n",
    "train_in_sentences=load_sentences(root_path,'train','in')\n",
    "train_out_sentences=load_sentences(root_path,'train','out')\n",
    "test_in_sentences=load_sentences(root_path,'test','in')\n",
    "test_out_sentences=load_sentences(root_path,'test','out')\n",
    "\n",
    "assert len(train_in_sentences)==len(train_out_sentences)\n",
    "assert len(test_in_sentences)==len(test_out_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laod_dataset(sentence_in,sentence_out,textfield):\n",
    "\n",
    "    len_sen=len(sentence_in)\n",
    "    examples=[]\n",
    "    fields = [('_in', textfield), ('_out', textfield)]\n",
    "    for i in range(len_sen):\n",
    "        examples.append(Example.fromlist([sentence_in[i], sentence_out[i]], fields))    \n",
    "    dataset = Dataset(examples, fields)\n",
    "    return dataset\n",
    "\n",
    "TEXT=Field(sequential=True,use_vocab=True,include_lengths=True)\n",
    "\n",
    "train_data=laod_dataset(train_in_sentences,train_out_sentences,textfield=TEXT)\n",
    "valid_data=laod_dataset(test_in_sentences,test_out_sentences,textfield=TEXT)\n",
    "\n",
    "BATCH_SIZE=512\n",
    "vectors = Vectors(name='../data/sgns.sikuquanshu.word') \n",
    "\n",
    "TEXT.build_vocab(train_data,vectors=vectors)\n",
    "\n",
    "train_iterator=BucketIterator(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    sort_key=lambda x: len(x.TEXT)\n",
    ")\n",
    "\n",
    "valid_iterator=BucketIterator(\n",
    "    valid_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=DEVICE,\n",
    "    sort_key=lambda x: len(x.TEXT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    #定义模型中使用的所有层\n",
    "    def __init__(self, vocab_size, embedding_dim=100, hidden_dim=120,):\n",
    "        #构造函数\n",
    "        super().__init__()\n",
    "        #embeddding层\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        #lstm层\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim,\n",
    "                           num_layers=1,\n",
    "                           bidirectional=True, \n",
    "\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, vocab_size)\n",
    "        self.softmax=nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, text,text_lengths):\n",
    "        embedded=self.embedding(text) #添加了padding的embedding结果\n",
    "\n",
    "        packed_embedded=pack_padded_sequence(embedded,text_lengths,batch_first=True,enforce_sorted=False)\n",
    "        packed_output,_=self.lstm(packed_embedded) #没有padding的输出\n",
    "        output,output_lengths=pad_packed_sequence(packed_output, batch_first=True) #返回输出，和没有padding的\n",
    "\n",
    "        output=self.fc(output)\n",
    "        # output=self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM=300\n",
    "HIDDEN_DIM = 300\n",
    "\n",
    "MODEL_NAME='BiLSTM'\n",
    "model=BiLSTM(\n",
    "    vocab_size=INPUT_DIM,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "     ).to(DEVICE)     \n",
    "\n",
    "\n",
    "# Embedding set\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "# dont no why use this ,set some vector to zero\n",
    "# model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.requires_grad = True\n",
    "\n",
    "#ignore the [PAD] index ,in pytorch is 1\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    correct=torch.tensor(correct.sum()).to(DEVICE)\n",
    "    all=torch.tensor(y.shape[0]).to(DEVICE)\n",
    "    return correct/ all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0  \n",
    "    model.train() \n",
    "    for batch in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        text=batch._in[0]\n",
    "        text=text.permute(1,0)\n",
    "        text_lengths=batch._in[1].cpu()\n",
    "\n",
    "        tags=batch._out[0]\n",
    "        tags=tags.permute(1,0)\n",
    "        predictions=model(text,text_lengths)\n",
    "\n",
    "\n",
    "        # flatten to the form predict:[batch_size*sentence_length,vocab_size],tag:[batch_size*sentence_length. Dont use the BATCH_SIZE because the last batch.\n",
    "        predictions=predictions.view(tags.shape[1]*tags.shape[0],-1)\n",
    "        tags = tags.reshape(tags.shape[1]*tags.shape[0])\n",
    "        acc = categorical_accuracy(predictions, tags)\n",
    "        loss = criterion(predictions,tags)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in tqdm(iterator):\n",
    "\n",
    "            text=batch._in[0]\n",
    "            text=text.permute(1,0)\n",
    "            text_lengths=batch._in[1].cpu()\n",
    "\n",
    "            tags=batch._out[0]\n",
    "            tags=tags.permute(1,0)\n",
    "            predictions=model(text,text_lengths)\n",
    "\n",
    "\n",
    "            # flatten to the form predict:[batch_size*sentence_length,vocab_size],tag:[batch_size*sentence_length. Dont use the BATCH_SIZE because the last batch.\n",
    "            predictions=predictions.view(tags.shape[1]*tags.shape[0],-1)\n",
    "            tags = tags.reshape(tags.shape[1]*tags.shape[0])\n",
    "            acc = categorical_accuracy(predictions, tags)\n",
    "\n",
    "            loss = criterion(predictions, tags)\n",
    "                            \n",
    "            acc = categorical_accuracy(predictions, tags)\n",
    "          \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmode():\n",
    "\n",
    "    N_EPOCHS = 30\n",
    "    best_valid_loss = float('inf')\n",
    "    train_loss_list=[]\n",
    "    valid_loss_list=[]\n",
    "    train_acc_list=[]\n",
    "    valid_acc_list=[]\n",
    "    train_pp_list=[]\n",
    "    valid_pp_list=[]\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        train_pp=np.exp(train_loss)\n",
    "        valid_pp=np.exp(valid_loss)\n",
    "        \n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), './model/model_all.pt')\n",
    "        \n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "        train_pp_list.append(train_pp)\n",
    "        valid_pp_list.append(valid_pp)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f}| Train PP: {train_pp:.2f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f}| Val PP: {valid_pp:.2f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "\n",
    "    def drawpic(train_loss_list=[],test_loss_list=[],epoch_number=10,title='1',root_path='./'):\n",
    "        # make data\n",
    "        x = [i for i in range(epoch_number)]\n",
    "        # plot\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(title)\n",
    "        ax.plot(x, train_loss_list, linewidth=2.0)\n",
    "        ax.plot(x, test_loss_list, linewidth=2.0)\n",
    "        path=root_path+title+'.jpg'\n",
    "        print('![]({})'.format(path))\n",
    "        plt.savefig(path)\n",
    "        plt.show()\n",
    "    root_path='./pic/'\n",
    "    title='{}-loss-{}'.format(MODEL_NAME,str(N_EPOCHS))\n",
    "\n",
    "    drawpic(train_loss_list=train_loss_list,test_loss_list=valid_loss_list,epoch_number=N_EPOCHS,title=title,root_path=root_path)\n",
    "\n",
    "    title='{}-acc-{}'.format(MODEL_NAME,str(N_EPOCHS))\n",
    "\n",
    "    drawpic(train_loss_list=train_acc_list,test_loss_list=valid_acc_list,epoch_number=N_EPOCHS,title=title,root_path=root_path)\n",
    "\n",
    "    title='{}-PP-{}'.format(MODEL_NAME,str(N_EPOCHS))\n",
    "\n",
    "    drawpic(train_loss_list=train_pp_list,test_loss_list=valid_pp_list,epoch_number=N_EPOCHS,title=title,root_path=root_path)\n",
    "\n",
    "trainmode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru=BiLSTM(\n",
    "    vocab_size=INPUT_DIM,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "     ).to(DEVICE)   \n",
    "\n",
    "model_gru.load_state_dict(torch.load('./model/model_all.pt'))\n",
    "torch.save(model_gru, './model/model-all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(\"./data/vocab.csv\", \"w\")\n",
    "a_dict = dict(TEXT.vocab.stoi)\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in a_dict.items():\n",
    "    writer.writerow([value, key])\n",
    "a_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"./data/vocab.csv\", \"r\")\n",
    "reader = csv.reader(a_file)\n",
    "itos = {int(rows[0]):rows[1] for rows in reader}\n",
    "stoi=dict(zip(itos.values(), itos.keys()))\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('./model/model-all.pt',map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上联: 图画里，龙不吟虎不啸，小小书僮可笑可笑\n",
      "下联: 山山中，马能画人之鸣，大大学子能何何歌\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence='图画里，龙不吟虎不啸，小小书僮可笑可笑'\n",
    "print('上联:',sentence)\n",
    "sen_list=list(sentence)\n",
    "sen_len=len(sen_list)\n",
    "sen_size=[sen_len]\n",
    "indexed = [TEXT.vocab.stoi[t] for t in sen_list] \n",
    "\n",
    "tensor = torch.LongTensor(indexed).to(DEVICE)              #转换为张量\n",
    "tensor = tensor.unsqueeze(1).T  \n",
    "\n",
    "prediction = model(tensor,sen_size)\n",
    "max_preds = prediction.argmax(dim = 2, keepdim = True)\n",
    "max_preds=max_preds.reshape(sen_len)\n",
    "sen_predict=[TEXT.vocab.itos[t] for t in max_preds]\n",
    "sen_predict=''.join(sen_predict)\n",
    "print('下联:',sen_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上联: 关注嘉然，顿顿解馋\n",
      "下联: 天持美态，不可知香\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence='关注嘉然，顿顿解馋'\n",
    "print('上联:',sentence)\n",
    "sen_list=list(sentence)\n",
    "sen_len=len(sen_list)\n",
    "sen_size=[sen_len]\n",
    "indexed = [TEXT.vocab.stoi[t] for t in sen_list] \n",
    "\n",
    "tensor = torch.LongTensor(indexed).to(DEVICE)              #转换为张量\n",
    "tensor = tensor.unsqueeze(1).T  \n",
    "\n",
    "prediction = model_gru(tensor,sen_size)\n",
    "max_preds = prediction.argmax(dim = 2, keepdim = True)\n",
    "max_preds=max_preds.reshape(sen_len)\n",
    "sen_predict=[TEXT.vocab.itos[t] for t in max_preds]\n",
    "sen_predict=''.join(sen_predict)\n",
    "print('下联:',sen_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24c48bf01fbadd88fbac5618c32e2a5a96dabf55ba983d805c289156c801b6ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('zoro': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
